{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Euclidean Alignment + Weighted TL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('D:\\Google_Drive\\JupyterNotebookProjects\\bci-research\\plan_c\\csp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import moabb.datasets\n",
    "import moabb.paradigms\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "from csp.utils import subject_counter\n",
    "from csp.preprocess import fir_bandpass, apply_bandpass, fetch_left_right_EEG\n",
    "from csp.preprocess import split_EEG_one_class\n",
    "from csp.feat_extraction import compute_Z, feat_vector, true_label\n",
    "from csp.csp import CSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import the data\n",
    "\n",
    "# Number of subject, n + 1 for iteration purpose (there are 9 subjects)\n",
    "ns = 10\n",
    "\n",
    "# Creating dict to store original data and modified data\n",
    "# ori_data will serve as initial loaded data that will remain unchanged\n",
    "ori_data = dict()\n",
    "mod_data = dict() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iter over all data path then store them in sub0X variable\n",
    "for subj in range(1, 10):\n",
    "    data_path = '../../datasets/BCICIV2a/A{:02d}T.npz'.format(subj)\n",
    "    \n",
    "    # Load EEG data from datapath and store into subj0X variabel then store into ori_dict\n",
    "    # Then also fetch 's' (EEG data) into mod_data\n",
    "    ori_data[subj] = np.load(data_path)\n",
    "    mod_data[subj] = {}\n",
    "    mod_data[subj]['raw_EEG'] = deepcopy(ori_data[subj]['s'])\n",
    "    \n",
    "    # Remove last three EOG electrodes\n",
    "    mod_data[subj]['raw_EEG'] = np.delete(mod_data[subj]['raw_EEG'], np.s_[22:], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Bandpass Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import firwin, freqs, lfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency sampling at 250 Hz\n",
    "fs = 250\n",
    "\n",
    "# Applying bandpass filter 8-30 Hz to all subjects raw EEG\n",
    "b = fir_bandpass(51, low=8, high=30, fs=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREPROCESSING ##\n",
    "\n",
    "# Frequency sampling at 250 Hz\n",
    "fs = 250\n",
    "\n",
    "# Applying bandpass filter 8-30 Hz to all subjects raw EEG\n",
    "b = fir_bandpass(51, low=8, high=30, fs=fs)\n",
    "\n",
    "# Key to store result\n",
    "EEG_filtered = 'EEG_filtered'\n",
    "\n",
    "for subj in mod_data.keys():\n",
    "    temp_raw_EEG = mod_data[subj]['raw_EEG']\n",
    "    \n",
    "    mod_data[subj][EEG_filtered] = apply_bandpass(temp_raw_EEG, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Left and Right Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['raw_EEG', 'EEG_filtered', 'left_pos', 'right_pos', 'EEG_left', 'EEG_right'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_data[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for  1\n",
      "Processing for  2\n",
      "Processing for  3\n",
      "Processing for  4\n",
      "Processing for  5\n",
      "Processing for  6\n",
      "Processing for  7\n",
      "Processing for  8\n",
      "Processing for  9\n",
      "\t\tLeft \t\t Right\n",
      "subject01:\t(72, 22, 750)\t(72, 22, 750)\n",
      "subject02:\t(72, 22, 750)\t(72, 22, 750)\n",
      "subject03:\t(72, 22, 750)\t(72, 22, 750)\n",
      "subject04:\t(72, 22, 750)\t(72, 22, 750)\n",
      "subject05:\t(72, 22, 750)\t(72, 22, 750)\n",
      "subject06:\t(72, 22, 750)\t(72, 22, 750)\n",
      "subject07:\t(72, 22, 750)\t(72, 22, 750)\n",
      "subject08:\t(72, 22, 750)\t(72, 22, 750)\n",
      "subject09:\t(72, 22, 750)\t(72, 22, 750)\n"
     ]
    }
   ],
   "source": [
    "## Only fetch left and right class\n",
    "mod_data = fetch_left_right_EEG(mod_data, ori_data=ori_data)\n",
    "    \n",
    "# Checking current size of EEG left and right data\n",
    "print('\\t\\tLeft \\t\\t Right')\n",
    "\n",
    "for subj in mod_data.keys():\n",
    "    \n",
    "    temp = mod_data[subj]\n",
    "    print('subject{:02d}:\\t{}\\t{}'.format(subj, temp['EEG_left'].shape, temp['EEG_right'].shape)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Data Alignment on raw EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_data[1]['raw_EEG']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library\n",
    "from scipy.linalg import sqrtm, inv \n",
    "\n",
    "def apply_EA(data, key_list):\n",
    "    '''\n",
    "    Apply Euclidean aligment on array-like objects for 1 subject\n",
    "    \n",
    "    PARAMETER:\n",
    "    data:\n",
    "    dictionary containing left and right EEG data of each subject\n",
    "    \n",
    "    key_list:\n",
    "    keys inside dict in which data that is about to be aligned are stored\n",
    "    \n",
    "    OUTPUT:\n",
    "    dictionary data with aligned version of key_list\n",
    "    '''\n",
    "    \n",
    "    # Processing each value in key_list\n",
    "    for key in key_list:\n",
    "        all_trials = data[key]\n",
    "\n",
    "        # Calculate reference matrix\n",
    "        R = 0\n",
    "\n",
    "        # Iterate over all trials\n",
    "        for trial in all_trials:\n",
    "            cov = trial@trial.T\n",
    "            R += cov\n",
    "\n",
    "        # Average over all trials\n",
    "        R = R/all_trials.shape[0]\n",
    "\n",
    "        # Compute R^(-0.5)\n",
    "        R_inv = sqrtm(inv(R))\n",
    "\n",
    "        # Perform alignment on each trial\n",
    "        X_hat = []\n",
    "        for trial in all_trials:\n",
    "            X_hat.append(R_inv@trial)\n",
    "\n",
    "        # Store as a new key in data dictionary\n",
    "        # alg stands for aligned\n",
    "        new_key = key + str('_alg')\n",
    "        print('name of new key ', new_key)\n",
    "\n",
    "        data[new_key] = np.array(X_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject  1\n",
      "name of new key  EEG_left_alg\n",
      "name of new key  EEG_right_alg\n",
      "\n",
      "Processing subject  2\n",
      "name of new key  EEG_left_alg\n",
      "name of new key  EEG_right_alg\n",
      "\n",
      "Processing subject  3\n",
      "name of new key  EEG_left_alg\n",
      "name of new key  EEG_right_alg\n",
      "\n",
      "Processing subject  4\n",
      "name of new key  EEG_left_alg\n",
      "name of new key  EEG_right_alg\n",
      "\n",
      "Processing subject  5\n",
      "name of new key  EEG_left_alg\n",
      "name of new key  EEG_right_alg\n",
      "\n",
      "Processing subject  6\n",
      "name of new key  EEG_left_alg\n",
      "name of new key  EEG_right_alg\n",
      "\n",
      "Processing subject  7\n",
      "name of new key  EEG_left_alg\n",
      "name of new key  EEG_right_alg\n",
      "\n",
      "Processing subject  8\n",
      "name of new key  EEG_left_alg\n",
      "name of new key  EEG_right_alg\n",
      "\n",
      "Processing subject  9\n",
      "name of new key  EEG_left_alg\n",
      "name of new key  EEG_right_alg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all subjects to compute the aligned EEG trials\n",
    "# Define keys to be processed\n",
    "process_key = ['EEG_left', 'EEG_right']\n",
    "\n",
    "for subj in mod_data.keys():\n",
    "    print('Processing subject ', subj)\n",
    "    apply_EA(mod_data[subj], process_key)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_alg = mod_data[3]['EEG_left_alg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 22, 750)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_alg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr in left_alg:\n",
    "    summ += tr@tr.T\n",
    "    \n",
    "I = summ/left_alg.shape[0]\n",
    "I = pd.DataFrame(np.round(I, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9   ...   12   13   14   15  \\\n",
       "0   1.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  0.0  ... -0.0 -0.0 -0.0 -0.0   \n",
       "1  -0.0  1.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  ... -0.0 -0.0  0.0 -0.0   \n",
       "2  -0.0 -0.0  1.0 -0.0 -0.0  0.0 -0.0 -0.0  0.0 -0.0  ... -0.0 -0.0 -0.0  0.0   \n",
       "3  -0.0 -0.0 -0.0  1.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0  ... -0.0 -0.0  0.0  0.0   \n",
       "4  -0.0 -0.0 -0.0  0.0  1.0 -0.0 -0.0  0.0 -0.0 -0.0  ... -0.0 -0.0  0.0  0.0   \n",
       "5  -0.0 -0.0  0.0 -0.0 -0.0  1.0 -0.0 -0.0 -0.0 -0.0  ... -0.0 -0.0  0.0 -0.0   \n",
       "6  -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  1.0 -0.0  0.0 -0.0  ... -0.0 -0.0 -0.0  0.0   \n",
       "7  -0.0 -0.0 -0.0 -0.0  0.0 -0.0 -0.0  1.0 -0.0  0.0  ... -0.0  0.0 -0.0 -0.0   \n",
       "8  -0.0 -0.0  0.0 -0.0 -0.0 -0.0  0.0 -0.0  1.0 -0.0  ... -0.0 -0.0  0.0 -0.0   \n",
       "9   0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  0.0 -0.0  1.0  ... -0.0  0.0 -0.0 -0.0   \n",
       "10  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  0.0  ... -0.0  0.0 -0.0 -0.0   \n",
       "11 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  0.0 -0.0  ... -0.0 -0.0 -0.0  0.0   \n",
       "12 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  ...  1.0 -0.0  0.0 -0.0   \n",
       "13 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  0.0 -0.0  0.0  ... -0.0  1.0  0.0 -0.0   \n",
       "14 -0.0  0.0 -0.0  0.0  0.0  0.0 -0.0 -0.0  0.0 -0.0  ...  0.0  0.0  1.0  0.0   \n",
       "15 -0.0 -0.0  0.0  0.0  0.0 -0.0  0.0 -0.0 -0.0 -0.0  ... -0.0 -0.0  0.0  1.0   \n",
       "16 -0.0 -0.0  0.0  0.0 -0.0  0.0 -0.0 -0.0  0.0 -0.0  ... -0.0  0.0 -0.0 -0.0   \n",
       "17 -0.0 -0.0  0.0 -0.0  0.0 -0.0 -0.0  0.0 -0.0  0.0  ...  0.0 -0.0  0.0  0.0   \n",
       "18  0.0 -0.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  ... -0.0 -0.0  0.0 -0.0   \n",
       "19 -0.0 -0.0 -0.0 -0.0  0.0 -0.0 -0.0  0.0 -0.0  0.0  ... -0.0 -0.0 -0.0 -0.0   \n",
       "20 -0.0 -0.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0  0.0 -0.0  ... -0.0 -0.0  0.0  0.0   \n",
       "21 -0.0 -0.0  0.0 -0.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0  ... -0.0 -0.0 -0.0  0.0   \n",
       "\n",
       "     16   17   18   19   20   21  \n",
       "0  -0.0 -0.0  0.0 -0.0 -0.0 -0.0  \n",
       "1  -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  \n",
       "2   0.0  0.0 -0.0 -0.0 -0.0  0.0  \n",
       "3   0.0 -0.0  0.0 -0.0  0.0 -0.0  \n",
       "4  -0.0  0.0 -0.0  0.0 -0.0 -0.0  \n",
       "5   0.0 -0.0 -0.0 -0.0 -0.0  0.0  \n",
       "6  -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  \n",
       "7  -0.0  0.0 -0.0  0.0 -0.0 -0.0  \n",
       "8   0.0 -0.0 -0.0 -0.0  0.0 -0.0  \n",
       "9  -0.0  0.0 -0.0  0.0 -0.0 -0.0  \n",
       "10  0.0  0.0 -0.0 -0.0 -0.0 -0.0  \n",
       "11 -0.0  0.0 -0.0 -0.0 -0.0 -0.0  \n",
       "12 -0.0  0.0 -0.0 -0.0 -0.0 -0.0  \n",
       "13  0.0 -0.0 -0.0 -0.0 -0.0 -0.0  \n",
       "14 -0.0  0.0  0.0 -0.0  0.0 -0.0  \n",
       "15 -0.0  0.0 -0.0 -0.0  0.0  0.0  \n",
       "16  1.0 -0.0  0.0  0.0 -0.0  0.0  \n",
       "17 -0.0  1.0  0.0  0.0  0.0 -0.0  \n",
       "18  0.0  0.0  1.0  0.0 -0.0 -0.0  \n",
       "19  0.0  0.0  0.0  1.0 -0.0 -0.0  \n",
       "20 -0.0  0.0 -0.0 -0.0  1.0 -0.0  \n",
       "21  0.0 -0.0 -0.0 -0.0 -0.0  1.0  \n",
       "\n",
       "[22 rows x 22 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject  1\n",
      "22.0\n",
      "Subject  2\n",
      "22.0\n",
      "Subject  3\n",
      "22.0\n",
      "Subject  4\n",
      "22.0\n",
      "Subject  5\n",
      "22.0\n",
      "Subject  6\n",
      "22.0\n",
      "Subject  7\n",
      "22.0\n",
      "Subject  8\n",
      "22.0\n",
      "Subject  9\n",
      "22.0\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "for subj in mod_data.keys():\n",
    "    summ = 0\n",
    "    \n",
    "    print('Subject ', subj)\n",
    "    left_alg = mod_data[subj]['EEG_left_alg']\n",
    "    right_alg = mod_data[subj]['EEG_right_alg']\n",
    "    \n",
    "    for tr in left_alg:\n",
    "        summ += tr@tr.T\n",
    "    \n",
    "    I = summ/left_alg.shape[0]\n",
    "    I = pd.DataFrame(np.round(I, 2))\n",
    "    \n",
    "    # Sum up all matrix elements should equal to number of eeg channels, i.e. 22\n",
    "    assert (I.sum().sum() == 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing split for subject01\n",
      "Processing split for subject02\n",
      "Processing split for subject03\n",
      "Processing split for subject04\n",
      "Processing split for subject05\n",
      "Processing split for subject06\n",
      "Processing split for subject07\n",
      "Processing split for subject08\n",
      "Processing split for subject09\n"
     ]
    }
   ],
   "source": [
    "## Split to train and test data\n",
    "for subj in mod_data.keys():\n",
    "    print('Processing split for', subj)\n",
    "    \n",
    "    mod_data[subj]['EEG_left_train'], mod_data[subj]['EEG_left_test'] = split_EEG_one_class(mod_data[subj]['EEG_left'], 0.8)\n",
    "    mod_data[subj]['EEG_right_train'], mod_data[subj]['EEG_right_test'] = split_EEG_one_class(mod_data[subj]['EEG_right'], 0.8)     \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tLeft \t\t Right\n",
      "TRAINING\n",
      "subject01:\t(58, 22, 750)\t(58, 22, 750)\n",
      "subject02:\t(58, 22, 750)\t(58, 22, 750)\n",
      "subject03:\t(58, 22, 750)\t(58, 22, 750)\n",
      "subject04:\t(58, 22, 750)\t(58, 22, 750)\n",
      "subject05:\t(58, 22, 750)\t(58, 22, 750)\n",
      "subject06:\t(58, 22, 750)\t(58, 22, 750)\n",
      "subject07:\t(58, 22, 750)\t(58, 22, 750)\n",
      "subject08:\t(58, 22, 750)\t(58, 22, 750)\n",
      "subject09:\t(58, 22, 750)\t(58, 22, 750)\n",
      "TEST\n",
      "subject01:\t(14, 22, 750)\t(14, 22, 750)\n",
      "subject02:\t(14, 22, 750)\t(14, 22, 750)\n",
      "subject03:\t(14, 22, 750)\t(14, 22, 750)\n",
      "subject04:\t(14, 22, 750)\t(14, 22, 750)\n",
      "subject05:\t(14, 22, 750)\t(14, 22, 750)\n",
      "subject06:\t(14, 22, 750)\t(14, 22, 750)\n",
      "subject07:\t(14, 22, 750)\t(14, 22, 750)\n",
      "subject08:\t(14, 22, 750)\t(14, 22, 750)\n",
      "subject09:\t(14, 22, 750)\t(14, 22, 750)\n"
     ]
    }
   ],
   "source": [
    "# Checking size of EEG left and right data training and test data\n",
    "print('\\t\\tLeft \\t\\t Right')\n",
    "print('TRAINING')\n",
    "for i in range(1, ns):\n",
    "    \n",
    "    subj = subject_counter(i)\n",
    "    temp = mod_data[subj]\n",
    "    \n",
    "    print('subject{:02d}:\\t{}\\t{}'.format(i, temp['EEG_left_train'].shape, temp['EEG_right_train'].shape))\n",
    "\n",
    "print('TEST')\n",
    "for i in range(1, ns):\n",
    "    \n",
    "    subj = subject_counter(i)\n",
    "    temp = mod_data[subj]\n",
    "    \n",
    "    print('subject{:02d}:\\t{}\\t{}'.format(i, temp['EEG_left_test'].shape, temp['EEG_right_test'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cov for  subject01\n",
      "---------------------------\n",
      "Computing covariance of each class and composite covariance\n",
      "Computing eigenval, eigenvec, and whitening matrix of composite covariance \n",
      "Generating common eigenvector from each class\n",
      "Spatial filter for  subject01\n",
      " \n",
      "Computing cov for  subject02\n",
      "---------------------------\n",
      "Computing covariance of each class and composite covariance\n",
      "Computing eigenval, eigenvec, and whitening matrix of composite covariance \n",
      "Generating common eigenvector from each class\n",
      "Spatial filter for  subject02\n",
      " \n",
      "Computing cov for  subject03\n",
      "---------------------------\n",
      "Computing covariance of each class and composite covariance\n",
      "Computing eigenval, eigenvec, and whitening matrix of composite covariance \n",
      "Generating common eigenvector from each class\n",
      "Spatial filter for  subject03\n",
      " \n",
      "Computing cov for  subject04\n",
      "---------------------------\n",
      "Computing covariance of each class and composite covariance\n",
      "Computing eigenval, eigenvec, and whitening matrix of composite covariance \n",
      "Generating common eigenvector from each class\n",
      "Spatial filter for  subject04\n",
      " \n",
      "Computing cov for  subject05\n",
      "---------------------------\n",
      "Computing covariance of each class and composite covariance\n",
      "Computing eigenval, eigenvec, and whitening matrix of composite covariance \n",
      "Generating common eigenvector from each class\n",
      "Spatial filter for  subject05\n",
      " \n",
      "Computing cov for  subject06\n",
      "---------------------------\n",
      "Computing covariance of each class and composite covariance\n",
      "Computing eigenval, eigenvec, and whitening matrix of composite covariance \n",
      "Generating common eigenvector from each class\n",
      "Spatial filter for  subject06\n",
      " \n",
      "Computing cov for  subject07\n",
      "---------------------------\n",
      "Computing covariance of each class and composite covariance\n",
      "Computing eigenval, eigenvec, and whitening matrix of composite covariance \n",
      "Generating common eigenvector from each class\n",
      "Spatial filter for  subject07\n",
      " \n",
      "Computing cov for  subject08\n",
      "---------------------------\n",
      "Computing covariance of each class and composite covariance\n",
      "Computing eigenval, eigenvec, and whitening matrix of composite covariance \n",
      "Generating common eigenvector from each class\n",
      "Spatial filter for  subject08\n",
      " \n",
      "Computing cov for  subject09\n",
      "---------------------------\n",
      "Computing covariance of each class and composite covariance\n",
      "Computing eigenval, eigenvec, and whitening matrix of composite covariance \n",
      "Generating common eigenvector from each class\n",
      "Spatial filter for  subject09\n",
      " \n"
     ]
    }
   ],
   "source": [
    "csp = CSP()\n",
    "\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    print('Computing cov for ', subj)\n",
    "    print('---------------------------')\n",
    "    \n",
    "    mod_data[subj]['CSP'] = {}\n",
    "    \n",
    "    # Covariance\n",
    "    print('Computing covariance of each class and composite covariance')\n",
    "    mod_data[subj]['CSP']['cov_left'] = csp.compute_cov(mod_data[subj]['EEG_left_train'])\n",
    "    mod_data[subj]['CSP']['cov_right'] = csp.compute_cov(mod_data[subj]['EEG_right_train'])\n",
    "    mod_data[subj]['CSP']['cov_comp']  = mod_data[subj]['CSP']['cov_left'] + mod_data[subj]['CSP']['cov_right']\n",
    "    \n",
    "    # Whitening matrix\n",
    "    print('Computing eigenval, eigenvec, and whitening matrix of composite covariance ')\n",
    "    mod_data[subj]['CSP']['whitening'] = {}\n",
    "    \n",
    "    \n",
    "    # Decomposing composite covariance into eigenvector and eigenvalue\n",
    "    temp_whitening = mod_data[subj]['CSP']['whitening']\n",
    "    temp_cov = mod_data[subj]['CSP']['cov_comp']\n",
    "    \n",
    "    temp_whitening['eigval'], temp_whitening['eigvec'] = csp.decompose_cov(temp_cov)\n",
    "\n",
    "    # White matrix\n",
    "    temp_whitening['P'] = csp.white_matrix(temp_whitening['eigval'], temp_whitening['eigvec'])\n",
    "    \n",
    "    # Common eigenvec from Sl and Sr\n",
    "    print('Generating common eigenvector from each class')\n",
    "    mod_data[subj]['CSP']['S_left'] = {}\n",
    "    mod_data[subj]['CSP']['S_right'] = {}  \n",
    "    \n",
    "    # Where to access data\n",
    "    temp_P = mod_data[subj]['CSP']['whitening']['P']\n",
    "    Cl = mod_data[subj]['CSP']['cov_left']\n",
    "    Cr = mod_data[subj]['CSP']['cov_right']\n",
    "    \n",
    "    # Where to store result\n",
    "    temp_Sl = mod_data[subj]['CSP']['S_left']\n",
    "    temp_Sr = mod_data[subj]['CSP']['S_right']\n",
    "\n",
    "    # LEFT\n",
    "    Sl = csp.compute_S(Cl, temp_P)\n",
    "    temp_Sl['eigvec'], temp_Sl['eigval'] = csp.decompose_S(Sl, 'descending')\n",
    "    \n",
    "    # RIGHT\n",
    "    Sr = csp.compute_S(Cr, temp_P)\n",
    "    temp_Sr['eigvec'], temp_Sr['eigval'] = csp.decompose_S(Sr, 'ascending')   \n",
    "    \n",
    "    # Spatial filter\n",
    "    print('Spatial filter for ',subj)\n",
    "    temp_eigvec = mod_data[subj]['CSP']['S_left']['eigvec']\n",
    "    temp_P = mod_data[subj]['CSP']['whitening']['P']\n",
    "    \n",
    "    mod_data[subj]['CSP']['W'] = csp.spatial_filter(temp_eigvec, temp_P)\n",
    "    \n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training vector for  subject01\n",
      "Training dataset shape (116, 5)\n",
      "\n",
      "Generating training vector for  subject02\n",
      "Training dataset shape (116, 5)\n",
      "\n",
      "Generating training vector for  subject03\n",
      "Training dataset shape (116, 5)\n",
      "\n",
      "Generating training vector for  subject04\n",
      "Training dataset shape (116, 5)\n",
      "\n",
      "Generating training vector for  subject05\n",
      "Training dataset shape (116, 5)\n",
      "\n",
      "Generating training vector for  subject06\n",
      "Training dataset shape (116, 5)\n",
      "\n",
      "Generating training vector for  subject07\n",
      "Training dataset shape (116, 5)\n",
      "\n",
      "Generating training vector for  subject08\n",
      "Training dataset shape (116, 5)\n",
      "\n",
      "Generating training vector for  subject09\n",
      "Training dataset shape (116, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select number of filter\n",
    "m = 2\n",
    "\n",
    "# Seed to fix randomization\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create new keys for trainning and test feature vector\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    print('Generating training vector for ', subj)\n",
    "    \n",
    "    mod_data[subj]['train']= {}  \n",
    "\n",
    "    temp_W = mod_data[subj]['CSP']['W']\n",
    "    temp_EEG_left = mod_data[subj]['EEG_left_train']\n",
    "    temp_EEG_right = mod_data[subj]['EEG_right_train']\n",
    "    \n",
    "    # LEFT\n",
    "    mod_data[subj]['train']['Z_left'] = compute_Z(temp_W, temp_EEG_left, m)\n",
    "    mod_data[subj]['train']['feat_left'] = feat_vector(mod_data[subj]['train']['Z_left'])\n",
    "    left_label = true_label(mod_data[subj]['train']['feat_left'], hand='left')\n",
    "    \n",
    "    # RIGHT\n",
    "    mod_data[subj]['train']['Z_right'] = compute_Z(temp_W, temp_EEG_right, m)\n",
    "    mod_data[subj]['train']['feat_right'] = feat_vector(mod_data[subj]['train']['Z_right'])     \n",
    "    right_label = true_label(mod_data[subj]['train']['feat_right'], hand='right')\n",
    "\n",
    "    # Combine all trials and labels\n",
    "    left = np.concatenate([mod_data[subj]['train']['feat_left'], left_label], axis=1)\n",
    "    right = np.concatenate([mod_data[subj]['train']['feat_right'], right_label], axis=1)\n",
    "\n",
    "    # Combine all left and right trials\n",
    "    mod_data[subj]['train']['feat_train'] = np.vstack([left, right])\n",
    "    \n",
    "    np.random.shuffle(mod_data[subj]['train']['feat_train'])\n",
    "    \n",
    "    print('Training dataset shape {}\\n'.format(mod_data[subj]['train']['feat_train'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.80850967, -0.6600156 , -0.48623359, -0.52374037,  1.        ],\n",
       "       [-0.40809937, -0.50156184, -0.85628869, -0.80985649,  0.        ],\n",
       "       [-0.45061195, -0.53515375, -0.78251033, -0.72343572,  0.        ],\n",
       "       [-0.62933009, -0.5755371 , -0.46896779, -0.79636582,  0.        ],\n",
       "       [-0.7143548 , -0.53946605, -0.52948956, -0.65221154,  0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_data['subject01']['train']['feat_train'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test vector for  subject01\n",
      "Test dataset shape (28, 5)\n",
      "\n",
      "Generating test vector for  subject02\n",
      "Test dataset shape (28, 5)\n",
      "\n",
      "Generating test vector for  subject03\n",
      "Test dataset shape (28, 5)\n",
      "\n",
      "Generating test vector for  subject04\n",
      "Test dataset shape (28, 5)\n",
      "\n",
      "Generating test vector for  subject05\n",
      "Test dataset shape (28, 5)\n",
      "\n",
      "Generating test vector for  subject06\n",
      "Test dataset shape (28, 5)\n",
      "\n",
      "Generating test vector for  subject07\n",
      "Test dataset shape (28, 5)\n",
      "\n",
      "Generating test vector for  subject08\n",
      "Test dataset shape (28, 5)\n",
      "\n",
      "Generating test vector for  subject09\n",
      "Test dataset shape (28, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create new keys for test feature vector\n",
    "np.random.seed(42)\n",
    "\n",
    "for i in range(1, ns):\n",
    "    subj = subject_counter(i)\n",
    "    \n",
    "    print('Generating test vector for ', subj)\n",
    "    \n",
    "    mod_data[subj]['test']= {}  \n",
    "\n",
    "    temp_W = mod_data[subj]['CSP']['W']\n",
    "    temp_EEG_left = mod_data[subj]['EEG_left_test']\n",
    "    temp_EEG_right = mod_data[subj]['EEG_right_test']\n",
    "      \n",
    "    # LEFT\n",
    "    mod_data[subj]['test']['Z_left'] = compute_Z(temp_W, temp_EEG_left, m)\n",
    "    mod_data[subj]['test']['feat_left'] = feat_vector(mod_data[subj]['test']['Z_left'])\n",
    "    left_label = true_label(mod_data[subj]['test']['feat_left'], hand='left')\n",
    "    \n",
    "    # RIGHT\n",
    "    mod_data[subj]['test']['Z_right'] = compute_Z(temp_W, temp_EEG_right, m)\n",
    "    mod_data[subj]['test']['feat_right'] = feat_vector(mod_data[subj]['test']['Z_right'])     \n",
    "    right_label = true_label(mod_data[subj]['test']['feat_right'], hand='right')\n",
    "\n",
    "    # Combine all trials and labels\n",
    "    left = np.concatenate([mod_data[subj]['test']['feat_left'], left_label], axis=1)\n",
    "    right = np.concatenate([mod_data[subj]['test']['feat_right'], right_label], axis=1)\n",
    "\n",
    "    # Combine all left and right trials\n",
    "    mod_data[subj]['test']['feat_test'] = np.vstack([left, right])\n",
    "    \n",
    "    np.random.shuffle(mod_data[subj]['test']['feat_test'])\n",
    "    \n",
    "    print('Test dataset shape {}\\n'.format(mod_data[subj]['test']['feat_test'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "First, grab only 'session_T' then divide eeg_data (X) into left and right hand   \n",
    "In this early experiment subject 1 and 2 will be used as target while the rest as sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 22, 751)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_data[1]['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only take data belonging to session_T, do this for all subjects\n",
    "from copy import deepcopy\n",
    "all_data = deepcopy(ori_data)\n",
    "\n",
    "for subj in range(1, 10):\n",
    "    idx = all_data[subj]['meta'][all_data[subj]['meta'].session == 'session_T'].index.values\n",
    "    all_data[subj]['X'] = all_data[subj]['X'][idx]\n",
    "    all_data[subj]['X'] = all_data[subj]['X'].reshape(all_data[subj]['X'].shape[0], all_data[subj]['X'].shape[1], all_data[subj]['X'].shape[2])\n",
    "    all_data[subj]['y'] = all_data[subj]['y'][idx]\n",
    "    \n",
    "    # Divide them into left and right hand\n",
    "    all_data[subj]['left_hand'] = all_data[subj]['X'][all_data[subj]['y'] == 'left_hand']\n",
    "    all_data[subj]['right_hand'] = all_data[subj]['X'][all_data[subj]['y'] == 'right_hand']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 22, 751)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[1]['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.14191696, -11.40696936, -11.21258134,  -8.68376597,\n",
       "        -4.59912832,  -0.07569719,   3.82230888,   6.37972667,\n",
       "         7.34021711,   6.84364185,   5.27707906,   3.13170091,\n",
       "         0.90441751,  -0.97811483,  -2.24226967,  -2.83512959,\n",
       "        -2.91667921,  -2.75111618,  -2.55369506,  -2.39425553,\n",
       "        -2.21951115,  -1.96513015,  -1.65853343,  -1.41987996,\n",
       "        -1.3510833 ,  -1.3986444 ,  -1.30718873,  -0.72060542,\n",
       "         0.61540869,   2.66583416,   5.04424169,   7.11533515,\n",
       "         8.21400666,   7.88211124,   6.03172741,   2.98828778,\n",
       "        -0.58888536,  -3.88415456,  -6.15702562,  -6.96137681,\n",
       "        -6.27615009,  -4.49536536,  -2.28072811,  -0.33397538,\n",
       "         0.82926733,   1.02836715,   0.4405955 ,  -0.5073915 ,\n",
       "        -1.33304814,  -1.69128295])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[1]['left_hand'][0][0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98242\n",
      "100250\n",
      "112163\n",
      "114058\n",
      "116030\n",
      "124069\n",
      "126135\n",
      "130237\n",
      "140283\n",
      "154531\n",
      "168776\n",
      "186876\n",
      "189204\n",
      "191207\n",
      "197085\n",
      "201113\n",
      "208998\n",
      "214809\n",
      "229142\n",
      "239079\n",
      "245162\n",
      "251366\n",
      "261676\n",
      "283711\n",
      "289960\n",
      "297948\n",
      "299998\n",
      "313611\n",
      "321841\n",
      "333953\n",
      "346094\n",
      "348201\n",
      "354427\n",
      "364371\n",
      "376373\n",
      "380546\n",
      "384877\n",
      "386795\n",
      "398764\n",
      "402668\n",
      "404563\n",
      "430788\n",
      "442929\n",
      "447128\n",
      "451262\n",
      "455346\n",
      "459281\n",
      "469374\n",
      "481712\n",
      "489701\n",
      "491618\n",
      "505314\n",
      "529584\n",
      "537693\n",
      "541871\n",
      "546054\n",
      "548097\n",
      "550161\n",
      "552181\n",
      "572157\n",
      "576544\n",
      "600205\n",
      "622505\n",
      "626419\n",
      "632502\n",
      "636599\n",
      "642889\n",
      "646996\n",
      "654876\n",
      "663044\n",
      "666878\n",
      "671051\n"
     ]
    }
   ],
   "source": [
    "fs = 250\n",
    "mi_dur = 5\n",
    "\n",
    "left_hand = []\n",
    "for i in left_pos:\n",
    "    print(i)\n",
    "    left = X1['s'][i+int(fs*0.5): i + int(fs*3.5)]\n",
    "    left_hand.append(left.T)\n",
    "    \n",
    "left_hand = np.array(left_hand)\n",
    "#     right_hand = X1['s'][right_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-19.48242188, -16.65039062, -10.79101562, -15.0390625 ,\n",
       "       -15.57617188, -16.25976562, -14.01367188, -16.89453125,\n",
       "       -11.71875   , -11.08398438,  -3.36914062,  -5.90820312,\n",
       "         0.43945312,   5.51757812,   5.2734375 ,   4.78515625,\n",
       "         4.93164062,   9.27734375,   3.95507812,   4.44335938,\n",
       "        -6.15234375,  -9.08203125,  -9.27734375, -13.96484375,\n",
       "       -17.48046875, -18.75      , -24.95117188, -23.6328125 ,\n",
       "       -24.95117188, -23.73046875, -22.265625  , -20.65429688,\n",
       "       -22.11914062, -28.90625   , -26.41601562, -21.82617188,\n",
       "       -28.27148438, -24.4140625 , -17.578125  , -17.52929688,\n",
       "       -14.69726562,  -7.37304688,  -2.5390625 ,  -3.515625  ,\n",
       "        -6.93359375,  -8.69140625,  -7.95898438,  -2.24609375,\n",
       "        -6.00585938,  -4.93164062])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_hand[0][0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# trial_no = 60\n",
    "# assert np.all(all_data[1]['X'][trial_no][0].shape == ori_data[1]['X'][trial_no].shape)\n",
    "# assert np.all(all_data[1]['X'][trial_no][0] == ori_data[1]['X'][trial_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For subject: 1\n",
      "['right_hand' 'left_hand' 'left_hand' 'right_hand' 'right_hand']\n",
      "[1 0 0 1 1]\n",
      "\n",
      "For subject: 2\n",
      "['left_hand' 'right_hand' 'right_hand' 'left_hand' 'right_hand']\n",
      "[0 1 1 0 1]\n",
      "\n",
      "For subject: 3\n",
      "['left_hand' 'right_hand' 'right_hand' 'left_hand' 'right_hand']\n",
      "[0 1 1 0 1]\n",
      "\n",
      "For subject: 4\n",
      "['left_hand' 'left_hand' 'left_hand' 'right_hand' 'left_hand']\n",
      "[0 0 0 1 0]\n",
      "\n",
      "For subject: 5\n",
      "['left_hand' 'right_hand' 'right_hand' 'left_hand' 'right_hand']\n",
      "[0 1 1 0 1]\n",
      "\n",
      "For subject: 6\n",
      "['right_hand' 'right_hand' 'left_hand' 'right_hand' 'left_hand']\n",
      "[1 1 0 1 0]\n",
      "\n",
      "For subject: 7\n",
      "['left_hand' 'right_hand' 'right_hand' 'left_hand' 'right_hand']\n",
      "[0 1 1 0 1]\n",
      "\n",
      "For subject: 8\n",
      "['left_hand' 'right_hand' 'right_hand' 'left_hand' 'right_hand']\n",
      "[0 1 1 0 1]\n",
      "\n",
      "For subject: 9\n",
      "['right_hand' 'right_hand' 'left_hand' 'right_hand' 'left_hand']\n",
      "[1 1 0 1 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Currently label is still in string format change this to integer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "enc.fit(all_data[1]['y'])\n",
    "\n",
    "for i in all_data.keys():\n",
    "    print('For subject:', i)\n",
    "    print(all_data[i]['y'][:5])\n",
    "    \n",
    "    # Transform all label\n",
    "    all_data[i]['y'] = enc.transform(all_data[i]['y'])\n",
    "    \n",
    "    print(all_data[i]['y'][:5])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      session_T\n",
       "1      session_T\n",
       "2      session_T\n",
       "3      session_T\n",
       "4      session_T\n",
       "         ...    \n",
       "283    session_E\n",
       "284    session_E\n",
       "285    session_E\n",
       "286    session_E\n",
       "287    session_E\n",
       "Name: session, Length: 288, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_data[1]['meta'].session == 'session_T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check with the original data npz\n",
    "for i in range(1, 2):\n",
    "    X = np.load('../../datasets/BCICIV2a/A{:02d}T.npz'.format(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s', 'etyp', 'epos', 'edur', 'artifacts']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
